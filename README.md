[![forthebadge made-with-python](http://ForTheBadge.com/images/badges/made-with-python.svg)](https://www.python.org/)

# Visualizing-WhatsApp-Chats
Learning Data Analysis and Visualizing through WhatsApp Chats


### Importing Modules:
* re - for using regex expressions
* pandas - for exploiting dataframes
>````pip install pandas````
or visit PyPi site, by clicking [here](https://pypi.org/project/pandas/)
* matplotlib - for visualization (inline for ploting dataframes)
>````pip install matplotlib````
or visit PyPi site, by clicking [here](https://pypi.org/project/matplotlib/)
* Natural Language Toolkit
>````pip install nltk````
or visit PyPi site, by clicking [here](https://pypi.org/project/nltk/)

### Exporting chats:
Export WhatsApp chats as follows:
* Navigate to contact/group you want to export chat of
* Tap on the menu (3dots in the right corner)
* Tap on more and then tap on Export chat
* Choose WITHOUT MEDIA from the prompt
* Wait for a moment on the Initializing screen
* Share through mail or any other means
* Gather the exported text file

The text file should have a name as: WhatsApp Chat with ... .txt. Use the same in the filename variable

### Analysis:
* Sender List
* Sender Message Count
* Bar Chart showing messages sent by each sender
* Pie Chart showing messages sent by each sender
* Area Chart showing the total number of messages sent by dates
* Date on which maximum number of messages were sent
* Date on which minimum number of messages were sent
* Line Chart showing messaging frequency of each sender, datewise
* Bar Chart showing hourly messaging frequency

### Notes
This project was created and tested under Windows. Also, I've been using Anaconda

This project is still under development. Parts of the source codes may not be well documented.
Also suitable prompts may not be available for the user at the moment.

More features and fixes are yet to come. Meanwhile suggestions, ideas, bug reports are welcomed.

I am a python n00bie! I am still learning python! And a bit of Data Sciece too! I have tried my best to give in as much effort required (of course directly proportionate to my knowledge), for this project. Though, this needs more work to be done, especially optimizing the algorithm.

<br>***Kinjal Raykarmakar***
